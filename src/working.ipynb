{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Models, Sequential Data\n",
    "\n",
    "\n",
    "The likelihood of a sequence $(x_1, x_2,\\ldots,x_N)$ can be defined as a markov model of $M^{\\mathrm{th}}$ order by\n",
    "\n",
    "\\begin{equation}\n",
    "p(x_1,\\ldots,x_N) = p(x_1) p(x_2|x_1)\\ldots p(x_{M}|x_{M-1},\\ldots x_1)\\prod_{n=M}^N p(x_n| x_{n-1},\\ldots x_{n-M}).\n",
    "\\end{equation}\n",
    "\n",
    "The simplest order model where $M=1$ is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "p(x_1,\\ldots,x_N) = p(x_1) \\prod_{n=2}^N p(x_n | x_{n-1}).\n",
    "\\end{equation}\n",
    "\n",
    "For this model, if $x\\in\\mathcal{N}$ is discrete with $K$ possible values, we can define $p(x_n|x_{n-1})$ by the transition matrix $\\mathbf{A}: A_{ij}=p(x_n=i|x_{n-1}=j)$. This is a $K\\times K$ rank 2 tensor but because we know that\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_i p(x_n=i|x_{n-1}=j) = 1, \\forall j\n",
    "\\end{equation}\n",
    "\n",
    "there are $K-1$ free variables per row of $\\mathbf{A}$ and $K(K-1)$ free variables in total. For $M=1$,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{A} =\n",
    "\\begin{bmatrix}\n",
    "a_0 & 1-a_0 \\\\\n",
    "a_1 & 1-a_1\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     15,
     37
    ]
   },
   "outputs": [],
   "source": [
    "class ConditionalDistribution:\n",
    "    \"\"\"\n",
    "    Conditional probability distribution p(x_n | x_n-1, .., x_n-M) for \n",
    "    a M^th order Markox sequence.\n",
    "    \"\"\"\n",
    "    def __init__(self, K: int, M: int):\n",
    "        # number of possible categorical values\n",
    "        self.K = K\n",
    "        \n",
    "        # order of Markovian dependence\n",
    "        self.M = M\n",
    "        \n",
    "        # uniform initial values for transition probabilities\n",
    "        self.A = np.ones([self.K]*(M+1))/self.K\n",
    "        \n",
    "    def prob(self, *args) -> float:\n",
    "        \"\"\"\n",
    "        Return p(args[0]|args[1],args[2],..,args[M])\n",
    "        \n",
    "        args[0] = x_n\n",
    "        args[1] = x_n-1\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "        args[M] = x_n-M\n",
    "        \n",
    "        Assume that elements of *args are integers in the range 0 to K-1\n",
    "        inclusive.\n",
    "        \"\"\"\n",
    "        if len(args) != self.M+1:\n",
    "            raise Exception('Input shape doesnt match expected shape')\n",
    "            \n",
    "        return self.A[tuple(args)]\n",
    "    \n",
    "    def log_prob(self, *args) -> float:\n",
    "        return np.log(self.prob(*args))\n",
    "            \n",
    "    def grad_log_prob(self, *args) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns the gradient of ln p(x_n|x_n-1..) with respect to A\n",
    "        \"\"\"\n",
    "        out = np.zeros(self.A.shape)\n",
    "        out[tuple(args)] = 1.0/self.A[tuple(args)]\n",
    "        return out\n",
    "    \n",
    "    def get_params(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns 1-d array of free parameters. Order of indices is\n",
    "        \n",
    "        for \n",
    "        \"\"\"\n",
    "        # p(x_n=K-1 | x_n-1 = j) = 1 - sum_k=0^K-2 p(x_n=k | x_n-1 = j)\n",
    "        return np.reshape(self.A[:-1, ...], (-1, ))\n",
    "    \n",
    "    def set_params(self, A_small: np.ndarray):\n",
    "        \"\"\"\n",
    "        Set self.A, the (K,...,K) rank M tensor for conditional \n",
    "        transition probabilities from the (K-1, K, ..., K) rank M tensor\n",
    "        A_small.\n",
    "        \"\"\"\n",
    "        # rank M tensor, shape = (K-1, K, ...,K)\n",
    "        A = np.reshape(A_small, tuple([self.K-1]+[self.K]*self.M))\n",
    "        \n",
    "        # rank M tensor, shape = (1, K, ..., K)\n",
    "        A_ = 1.0 - np.reshape(np.sum(A, axis=0), tuple([1]+[self.K]*self.M))\n",
    "        \n",
    "        if self.M > 0:\n",
    "            # rank M tensor, shape = (K,...,K)\n",
    "            self.A = np.vstack((A, A_))\n",
    "        else:\n",
    "            self.A = np.hstack((A, A_))\n",
    "        \n",
    "            \n",
    "class MarkovModel:\n",
    "    def __init__(self, K: int, M: int):\n",
    "        self.K = k\n",
    "        self.M = M\n",
    "        \n",
    "        self.models = [ConditionalDistribution(K=K, M=_m) for _m in range(M+1)]\n",
    "        \n",
    "        \n",
    "    def log_likelihood(self, x: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Returns ln p(x0) + ln p(x1|x0) ... + ln p(x_M-1|...x0) + sum_n p(x_n | x_n-1...)\n",
    "        \"\"\"\n",
    "        # ln p(x0) +...+ ln p(x_M-1 | ...x0)\n",
    "        out = sum([self.models[_m].log_prob(*x[0:_m+1][::-1]) for _m in range(self.M)])\n",
    "        \n",
    "        for _n in range(self.M, x.shape[1]):\n",
    "            out += self.modles[self.M].log_prob(*x[_n-self.M:_n+1][::-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def _test_getset(K: int, M: int):\n",
    "    inst = ConditionalDistribution(K=K, M=M)\n",
    "    # make random\n",
    "    inst.A = np.random.normal(size=inst.A.shape)\n",
    "    # make positive\n",
    "    inst.A = np.exp(inst.A)\n",
    "    # normalize\n",
    "    norm = np.reshape(np.sum(inst.A, axis=0),tuple([1]+[K]*M))\n",
    "    norm = np.tile(norm, tuple([K]+[1]*M))\n",
    "    inst.A /= norm\n",
    "    \n",
    "    Aorig = deepcopy(inst.A)\n",
    "    inst.set_params(inst.get_params())\n",
    "    Arecon = deepcopy(inst.A)\n",
    "    return np.allclose(Aorig, Arecon)\n",
    "\n",
    "def test_getset():\n",
    "    out = [[_test_getset(K=_k, M=_m) for _m in range(5)] for _k in range(1, 4)]\n",
    "    assert np.all(out), 'mismstach between getter and setter'\n",
    "\n",
    "test_getset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
